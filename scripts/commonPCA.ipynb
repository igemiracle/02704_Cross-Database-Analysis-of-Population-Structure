{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2a6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hapmap_path = '../data/filtered_hapmap3'\n",
    "kg_path = '../data/1000g/populations'\n",
    "output_path = '../data/pca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b8c84fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after class definition on line 8 (2679352954.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[39], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, snp_mapping_file):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after class definition on line 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "class JointPopulationAnalyzer:\n",
    "def __init__(self, snp_mapping_file):\n",
    "    \"\"\"\n",
    "    Initialize with shared populations, data paths and SNP mapping file\n",
    "    \"\"\"\n",
    "    self.shared_populations = [\n",
    "        'ASW', 'CEU', 'CHB', 'JPT', \n",
    "        'LWK', 'MXL', 'TSI', 'YRI'\n",
    "    ]\n",
    "    \n",
    "    self.data_paths = {\n",
    "        'hapmap3': Path('../data/filtered_hapmap3'),\n",
    "        '1000g': Path('../data/1000g/populations')\n",
    "    }\n",
    "    \n",
    "    # Load SNP mapping and print structure\n",
    "    self.snp_mapping = pd.read_csv(snp_mapping_file, sep='\\t')\n",
    "    print(\"SNP mapping columns:\", self.snp_mapping.columns.tolist())\n",
    "    print(\"\\nFirst few rows of mapping file:\")\n",
    "    print(self.snp_mapping.head())\n",
    "    \n",
    "    # Store both HapMap3 and 1000G alleles\n",
    "    self.hapmap_to_1000g = {}\n",
    "    for _, row in self.snp_mapping.iterrows():\n",
    "        # We'll adjust these column names based on the debug output\n",
    "        self.hapmap_to_1000g[row['position']] = (\n",
    "            row['ref'],  # Using generic column names for now\n",
    "            row['alt']\n",
    "        )\n",
    "    def _read_geno_file(self, filepath):\n",
    "        \"\"\"Read genotype file with consistent dimensions\"\"\"\n",
    "        ind_file = str(filepath).replace('.geno', '.ind')\n",
    "        with open(ind_file, 'r') as f:\n",
    "            n_samples = sum(1 for line in f)\n",
    "        \n",
    "        print(f\"Reading genotype file: {filepath}\")\n",
    "        print(f\"Expected samples from .ind file: {n_samples}\")\n",
    "        \n",
    "        geno_lines = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for i, line in enumerate(f, 1):\n",
    "                line = line.strip()\n",
    "                numeric_line = []\n",
    "                for char in line[:n_samples]:\n",
    "                    if char in '012':\n",
    "                        numeric_line.append(int(char))\n",
    "                    else:\n",
    "                        numeric_line.append(-1)\n",
    "                        \n",
    "                while len(numeric_line) < n_samples:\n",
    "                    numeric_line.append(-1)\n",
    "                    \n",
    "                geno_lines.append(numeric_line)\n",
    "        \n",
    "        geno_array = np.array(geno_lines, dtype=np.int8)\n",
    "        print(f\"Final genotype matrix shape: {geno_array.shape}\")\n",
    "        \n",
    "        return geno_array\n",
    "\n",
    "    def load_genetic_data(self, population, dataset):\n",
    "        \"\"\"Load genetic data with position-based filtering\"\"\"\n",
    "        base_path = self.data_paths[dataset]\n",
    "        \n",
    "        try:\n",
    "            geno_path = base_path / f\"{population}.geno\"\n",
    "            ind_path = base_path / f\"{population}.ind\"\n",
    "            snp_path = base_path / f\"{population}.snp\"\n",
    "            \n",
    "            # Check files exist\n",
    "            for path in [geno_path, ind_path, snp_path]:\n",
    "                if not path.exists():\n",
    "                    print(f\"Missing file: {path}\")\n",
    "                    return None\n",
    "            \n",
    "            # Load data\n",
    "            geno = self._read_geno_file(geno_path)\n",
    "            \n",
    "            ind = pd.read_csv(ind_path, sep='\\s+', header=None,\n",
    "                            names=['sample_id', 'sex', 'population'])\n",
    "            \n",
    "            snp = pd.read_csv(snp_path, sep='\\s+', header=None,\n",
    "                            names=['id', 'chr', 'genetic_dist', 'position', 'ref', 'alt'])\n",
    "            \n",
    "            # Filter SNPs based on mapping\n",
    "            if dataset == 'hapmap3':\n",
    "                valid_positions = set(self.snp_mapping['position'])\n",
    "            else:  # 1000g\n",
    "                valid_positions = set(self.snp_mapping['position'])\n",
    "            \n",
    "            position_mask = snp['position'].isin(valid_positions)\n",
    "            filtered_geno = geno[position_mask]\n",
    "            filtered_snp = snp[position_mask]\n",
    "            \n",
    "            print(f\"Filtered from {len(snp)} to {len(filtered_snp)} SNPs based on mapping\")\n",
    "            \n",
    "            return {\n",
    "                'genotype': filtered_geno,\n",
    "                'individual': ind,\n",
    "                'snp': filtered_snp\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {population} from {dataset}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def identify_common_snps(self):\n",
    "        \"\"\"Identify SNPs common to all populations based on position mapping\"\"\"\n",
    "        common_positions = set(self.snp_mapping['position'])\n",
    "        print(f\"Using {len(common_positions)} mapped positions\")\n",
    "        return common_positions\n",
    "\n",
    "    def prepare_joint_analysis(self):\n",
    "        \"\"\"Prepare data for joint analysis\"\"\"\n",
    "        print(\"\\nLoading data for all populations...\")\n",
    "        \n",
    "        for dataset in self.data_paths.keys():\n",
    "            self.data[dataset] = {}\n",
    "            for pop in self.shared_populations:\n",
    "                print(f\"\\nProcessing {pop} from {dataset}...\")\n",
    "                data = self.load_genetic_data(pop, dataset)\n",
    "                if data is not None:\n",
    "                    self.data[dataset][pop] = data\n",
    "        \n",
    "        self.common_snps = self.identify_common_snps()\n",
    "        self.joint_data = self._prepare_joint_matrix()\n",
    "        print(f\"\\nFinal joint genotype matrix shape: {self.joint_data['genotype'].shape}\")\n",
    "\n",
    "    def _prepare_joint_matrix(self):\n",
    "        \"\"\"Prepare joint matrix using position-based mapping with detailed debugging\"\"\"\n",
    "        genotypes = []\n",
    "        pop_labels = []\n",
    "        dataset_labels = []\n",
    "        sample_ids = []\n",
    "\n",
    "        for dataset in self.data.keys():\n",
    "            for pop, pop_data in self.data[dataset].items():\n",
    "                if pop_data is None:\n",
    "                    print(f\"Skipping {pop}-{dataset}: No data\")\n",
    "                    continue\n",
    "\n",
    "                # Debug information\n",
    "                print(f\"\\nProcessing {pop}-{dataset}\")\n",
    "                print(f\"Original SNP count: {len(pop_data['snp'])}\")\n",
    "                print(f\"Original positions: {pop_data['snp']['position'].head()}\")\n",
    "                print(f\"Common SNP positions count: {len(self.common_snps)}\")\n",
    "\n",
    "                # Filter by mapped positions\n",
    "                snp_indices = pop_data['snp']['position'].isin(self.common_snps)\n",
    "                print(f\"Matched positions: {sum(snp_indices)}\")\n",
    "\n",
    "                if sum(snp_indices) == 0:\n",
    "                    print(f\"Warning: No matching positions found for {pop}-{dataset}\")\n",
    "                    continue\n",
    "\n",
    "                filtered_geno = pop_data['genotype'][snp_indices]\n",
    "                filtered_positions = pop_data['snp'].loc[snp_indices, 'position']\n",
    "\n",
    "                print(f\"Filtered genotype shape: {filtered_geno.shape}\")\n",
    "                print(f\"First few positions after filtering: {filtered_positions.head()}\")\n",
    "\n",
    "                # For 1000G data, check allele flipping\n",
    "                if dataset == '1000g':\n",
    "                    flip_count = 0\n",
    "                    for i, pos in enumerate(filtered_positions):\n",
    "                        if pos in self.hapmap_to_1000g:\n",
    "                            ref_kg, alt_kg = self.hapmap_to_1000g[pos]\n",
    "                            if ref_kg != pop_data['snp'].loc[snp_indices].iloc[i]['ref']:\n",
    "                                # Flip genotypes (0->2, 2->0, 1->1)\n",
    "                                mask = filtered_geno[i] != 1\n",
    "                                filtered_geno[i][mask] = 2 - filtered_geno[i][mask]\n",
    "                                flip_count += 1\n",
    "                    print(f\"Flipped genotypes for {flip_count} SNPs\")\n",
    "\n",
    "                # Only add if we have valid data\n",
    "                if filtered_geno.size > 0:\n",
    "                    genotypes.append(filtered_geno)\n",
    "                    n_samples = filtered_geno.shape[1]\n",
    "                    pop_labels.extend([pop] * n_samples)\n",
    "                    dataset_labels.extend([dataset] * n_samples)\n",
    "                    sample_ids.extend(pop_data['individual']['sample_id'])\n",
    "                    print(f\"Successfully added {pop}-{dataset}: {filtered_geno.shape}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Empty genotype matrix for {pop}-{dataset}\")\n",
    "\n",
    "        if not genotypes:\n",
    "            raise ValueError(\"No valid genotype data after filtering\")\n",
    "\n",
    "        # Check dimensions before concatenation\n",
    "        print(\"\\nFinal dimension check before concatenation:\")\n",
    "        for i, geno in enumerate(genotypes):\n",
    "            print(f\"Matrix {i}: shape {geno.shape}\")\n",
    "\n",
    "        try:\n",
    "            joint_geno = np.hstack(genotypes)\n",
    "            print(f\"Successfully created joint matrix with shape: {joint_geno.shape}\")\n",
    "        except Exception as e:\n",
    "            print(\"Error during concatenation:\")\n",
    "            print(str(e))\n",
    "            raise\n",
    "\n",
    "        return {\n",
    "            'genotype': joint_geno,\n",
    "            'population': np.array(pop_labels),\n",
    "            'dataset': np.array(dataset_labels),\n",
    "            'sample_id': np.array(sample_ids)\n",
    "        }\n",
    "    \n",
    "    def perform_pca(self, n_components=2):\n",
    "        \"\"\"\n",
    "        Perform PCA on the joint dataset\n",
    "\n",
    "        Args:\n",
    "            n_components: Number of principal components to compute\n",
    "        \"\"\"\n",
    "        print(\"Performing PCA analysis...\")\n",
    "\n",
    "        # Replace missing values with mean\n",
    "        genotype_data = self.joint_data['genotype'].copy()\n",
    "        mask = genotype_data == -1\n",
    "\n",
    "        for i in range(genotype_data.shape[0]):\n",
    "            row = genotype_data[i]\n",
    "            valid_values = row[row != -1]\n",
    "            if len(valid_values) > 0:\n",
    "                row_mean = np.mean(valid_values)\n",
    "                genotype_data[i][mask[i]] = row_mean\n",
    "\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(genotype_data.T)\n",
    "\n",
    "        # Perform PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        self.pca_results = pca.fit_transform(scaled_data)\n",
    "        self.explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "        print(f\"Variance explained: PC1={self.explained_variance[0]:.2%}, PC2={self.explained_variance[1]:.2%}\")\n",
    "\n",
    "    def plot_pca(self, save_path=None):\n",
    "        \"\"\"\n",
    "        Plot PCA results\n",
    "\n",
    "        Args:\n",
    "            save_path: Optional path to save the plot\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        # Plot each population-dataset combination\n",
    "        for pop in self.shared_populations:\n",
    "            for dataset in self.data_paths.keys():\n",
    "                mask = (self.joint_data['population'] == pop) & \\\n",
    "                      (self.joint_data['dataset'] == dataset)\n",
    "\n",
    "                if np.any(mask):  # Only plot if we have data for this combination\n",
    "                    plt.scatter(\n",
    "                        self.pca_results[mask, 0],\n",
    "                        self.pca_results[mask, 1],\n",
    "                        c=self.population_colors[pop],\n",
    "                        marker='o' if dataset == 'hapmap3' else '^',\n",
    "                        label=f'{pop}-{dataset}',\n",
    "                        alpha=0.7,\n",
    "                        s=50\n",
    "                    )\n",
    "\n",
    "        plt.xlabel(f'PC1 ({self.explained_variance[0]:.1%} variance)')\n",
    "        plt.ylabel(f'PC2 ({self.explained_variance[1]:.1%} variance)')\n",
    "        plt.title('PCA of HapMap3 and 1000G Populations')\n",
    "\n",
    "        # Add legend\n",
    "        legend_elements = []\n",
    "        for pop in self.shared_populations:\n",
    "            legend_elements.extend([\n",
    "                plt.Line2D([0], [0], marker='o', color='w', \n",
    "                          markerfacecolor=self.population_colors[pop],\n",
    "                          label=f'{pop}-HapMap3', markersize=8),\n",
    "                plt.Line2D([0], [0], marker='^', color='w', \n",
    "                          markerfacecolor=self.population_colors[pop],\n",
    "                          label=f'{pop}-1000G', markersize=8)\n",
    "            ])\n",
    "\n",
    "        plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), \n",
    "                  loc='upper left', borderaxespad=0.)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "            print(f\"Plot saved to {save_path}\")\n",
    "\n",
    "        plt.show()\n",
    "def run_analysis(snp_mapping_file):\n",
    "    \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "    try:\n",
    "        analyzer = JointPopulationAnalyzer(snp_mapping_file)\n",
    "        analyzer.prepare_joint_analysis()\n",
    "        analyzer.perform_pca()\n",
    "        analyzer.plot_pca(\"joint_population_pca.png\")\n",
    "        return analyzer\n",
    "    except Exception as e:\n",
    "        print(f\"Analysis failed: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f155fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "class JointPopulationAnalyzer:\n",
    "    def __init__(self, snp_mapping_file):\n",
    "        \"\"\"\n",
    "        Initialize with shared populations, data paths and SNP mapping file\n",
    "        \n",
    "        Args:\n",
    "            snp_mapping_file: Path to the SNP mapping file between HapMap3 and 1000G\n",
    "        \"\"\"\n",
    "        self.shared_populations = [\n",
    "            'ASW', 'CEU', 'CHB', 'JPT', \n",
    "            'LWK', 'MXL', 'TSI', 'YRI'\n",
    "        ]\n",
    "        \n",
    "        self.data_paths = {\n",
    "            'hapmap3': Path('../data/filtered_hapmap3'),\n",
    "            '1000g': Path('../data/1000g/populations')\n",
    "        }\n",
    "        \n",
    "        # Load SNP mapping with additional QC information\n",
    "        self.snp_mapping = pd.read_csv(snp_mapping_file, sep='\\t')\n",
    "        print(f\"Loaded {len(self.snp_mapping)} SNP mappings\")\n",
    "        \n",
    "        # Create enhanced lookup dictionaries\n",
    "        self.hapmap_to_1000g = dict(zip(\n",
    "            self.snp_mapping['position'], \n",
    "            zip(self.snp_mapping['ref_kg'], \n",
    "                self.snp_mapping['alt_kg'])\n",
    "        ))\n",
    "        \n",
    "        self.population_colors = {\n",
    "            'ASW': '#1f77b4', 'CEU': '#ff7f0e', 'CHB': '#2ca02c',\n",
    "            'JPT': '#d62728', 'LWK': '#9467bd', 'MXL': '#8c564b',\n",
    "            'TSI': '#e377c2', 'YRI': '#7f7f7f'\n",
    "        }\n",
    "        \n",
    "        self.data = {}\n",
    "\n",
    "    def _read_geno_file(self, filepath):\n",
    "        \"\"\"Read genotype file with enhanced QC\"\"\"\n",
    "        ind_file = str(filepath).replace('.geno', '.ind')\n",
    "        with open(ind_file, 'r') as f:\n",
    "            n_samples = sum(1 for line in f)\n",
    "\n",
    "        print(f\"Reading genotype file: {filepath}\")\n",
    "\n",
    "        # Read genotype data\n",
    "        geno_lines = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                numeric_line = np.array([int(char) if char in '012' else -1 \n",
    "                                       for char in line[:n_samples]])\n",
    "                geno_lines.append(numeric_line)\n",
    "\n",
    "        geno_array = np.array(geno_lines, dtype=np.int8)\n",
    "\n",
    "        # Basic QC metrics\n",
    "        valid_genotypes = geno_array != -1\n",
    "        missing_rate = 1 - np.mean(valid_genotypes, axis=1)\n",
    "\n",
    "        # Calculate MAF only for valid genotypes\n",
    "        het_freq = np.zeros(len(geno_array))\n",
    "        hom_alt_freq = np.zeros(len(geno_array))\n",
    "\n",
    "        for i in range(len(geno_array)):\n",
    "            valid_mask = valid_genotypes[i]\n",
    "            if np.any(valid_mask):\n",
    "                het_freq[i] = np.mean(geno_array[i][valid_mask] == 1)\n",
    "                hom_alt_freq[i] = np.mean(geno_array[i][valid_mask] == 2)\n",
    "\n",
    "        maf = hom_alt_freq + 0.5 * het_freq\n",
    "        maf = np.minimum(maf, 1 - maf)\n",
    "\n",
    "        # Filter SNPs with high missing rate or extreme MAF\n",
    "        valid_snps = (missing_rate < 0.05) & (maf > 0.01)\n",
    "        filtered_geno = geno_array[valid_snps]\n",
    "\n",
    "        print(f\"Removed {np.sum(~valid_snps)} SNPs failing QC\")\n",
    "        print(f\"Final genotype matrix shape: {filtered_geno.shape}\")\n",
    "\n",
    "        return filtered_geno, valid_snps\n",
    "\n",
    "    def load_genetic_data(self, population, dataset):\n",
    "        \"\"\"Load genetic data with enhanced QC\"\"\"\n",
    "        base_path = self.data_paths[dataset]\n",
    "\n",
    "        try:\n",
    "            geno_path = base_path / f\"{population}.geno\"\n",
    "            ind_path = base_path / f\"{population}.ind\"\n",
    "            snp_path = base_path / f\"{population}.snp\"\n",
    "\n",
    "            # Check files exist\n",
    "            for path in [geno_path, ind_path, snp_path]:\n",
    "                if not path.exists():\n",
    "                    print(f\"Missing file: {path}\")\n",
    "                    return None\n",
    "\n",
    "            # Load data with QC\n",
    "            geno, valid_snps = self._read_geno_file(geno_path)\n",
    "\n",
    "            # Load and filter SNP data\n",
    "            if dataset == 'hapmap3':\n",
    "                snp = pd.read_csv(snp_path, sep='\\s+', header=None,\n",
    "                                names=['id', 'chr', 'genetic_dist', 'position', 'ref', 'alt'])\n",
    "            else:\n",
    "                snp = pd.read_csv(snp_path, sep='\\s+', header=None,\n",
    "                                names=['chr', 'position', 'ref', 'alt', 'genetic_dist'])\n",
    "\n",
    "            snp = snp[valid_snps].reset_index(drop=True)\n",
    "\n",
    "            # Load individual data\n",
    "            ind = pd.read_csv(ind_path, sep='\\s+', header=None,\n",
    "                            names=['sample_id', 'sex', 'population'])\n",
    "\n",
    "            # Perform HWE test\n",
    "            hwe_pvals = self._perform_hardy_weinberg(geno)\n",
    "            hwe_mask = hwe_pvals > 1e-6\n",
    "\n",
    "            # Apply HWE filter\n",
    "            filtered_geno = geno[hwe_mask]\n",
    "            filtered_snp = snp[hwe_mask].reset_index(drop=True)\n",
    "\n",
    "            print(f\"Removed {np.sum(~hwe_mask)} SNPs failing HWE\")\n",
    "            print(f\"Final data shapes - Genotype: {filtered_geno.shape}, SNPs: {len(filtered_snp)}\")\n",
    "\n",
    "            return {\n",
    "                'genotype': filtered_geno,\n",
    "                'individual': ind,\n",
    "                'snp': filtered_snp\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {population} from {dataset}: {str(e)}\")\n",
    "            print(\"Full traceback:\", e.__traceback__)\n",
    "            return None\n",
    "\n",
    "    def _perform_hardy_weinberg(self, genotypes):\n",
    "        \"\"\"Perform Hardy-Weinberg equilibrium test\"\"\"\n",
    "        p_values = []\n",
    "\n",
    "        for snp_genotypes in genotypes:\n",
    "            valid_mask = snp_genotypes != -1\n",
    "            counts = np.bincount(snp_genotypes[valid_mask], minlength=3)\n",
    "\n",
    "            # Skip SNPs with insufficient data\n",
    "            if len(counts) < 3 or sum(counts) < 20:  # minimum sample size threshold\n",
    "                p_values.append(0)\n",
    "                continue\n",
    "\n",
    "            # Calculate expected frequencies\n",
    "            n = sum(counts)\n",
    "            p = (2 * counts[2] + counts[1]) / (2 * n)\n",
    "            q = 1 - p\n",
    "\n",
    "            exp = np.array([\n",
    "                n * q**2,  # Expected AA\n",
    "                n * 2 * p * q,  # Expected AB\n",
    "                n * p**2   # Expected BB\n",
    "            ])\n",
    "\n",
    "            # Avoid division by zero in chi-square test\n",
    "            if np.any(exp < 1):\n",
    "                p_values.append(0)\n",
    "                continue\n",
    "\n",
    "            # Chi-square test\n",
    "            chi2, p_value = stats.chisquare(counts, exp)\n",
    "            p_values.append(p_value)\n",
    "\n",
    "        return np.array(p_values)\n",
    "        \n",
    "    def prepare_joint_analysis(self):\n",
    "        \"\"\"Prepare data for joint analysis\"\"\"\n",
    "        print(\"\\nLoading data for all populations...\")\n",
    "        \n",
    "        for dataset in self.data_paths.keys():\n",
    "            self.data[dataset] = {}\n",
    "            for pop in self.shared_populations:\n",
    "                print(f\"\\nProcessing {pop} from {dataset}...\")\n",
    "                data = self.load_genetic_data(pop, dataset)\n",
    "                if data is not None:\n",
    "                    self.data[dataset][pop] = data\n",
    "        \n",
    "        self.common_snps = self.identify_common_snps()\n",
    "        self.joint_data = self._prepare_joint_matrix()\n",
    "        print(f\"\\nFinal joint genotype matrix shape: {self.joint_data['genotype'].shape}\")\n",
    "\n",
    "        \n",
    "    def identify_common_snps(self):\n",
    "        \"\"\"Identify SNPs common to all populations based on position mapping\"\"\"\n",
    "        common_positions = set(self.snp_mapping['position'])\n",
    "        print(f\"Using {len(common_positions)} mapped positions\")\n",
    "        return common_positions\n",
    "\n",
    " \n",
    "\n",
    "    def _prepare_joint_matrix(self):\n",
    "        \"\"\"Prepare joint matrix with improved SNP alignment\"\"\"\n",
    "        genotypes = []\n",
    "        pop_labels = []\n",
    "        dataset_labels = []\n",
    "        sample_ids = []\n",
    "\n",
    "        # Collect and sort positions\n",
    "        common_positions = self._get_common_positions()\n",
    "        print(f\"Found {len(common_positions)} common positions\")\n",
    "        \n",
    "        for dataset in self.data.keys():\n",
    "            for pop, pop_data in self.data[dataset].items():\n",
    "                if pop_data is None:\n",
    "                    continue\n",
    "\n",
    "                print(f\"\\nProcessing {pop}-{dataset}\")\n",
    "                \n",
    "                # Get position indices\n",
    "                pos_indices = [i for i, pos in enumerate(pop_data['snp']['position']) \n",
    "                             if pos in common_positions]\n",
    "                \n",
    "                geno = pop_data['genotype'][pos_indices]\n",
    "                snp_info = pop_data['snp'].iloc[pos_indices]\n",
    "                \n",
    "                # Handle allele flipping for 1000G\n",
    "                if dataset == '1000g':\n",
    "                    for i, (pos, ref, alt) in enumerate(zip(snp_info['position'], \n",
    "                                                          snp_info['ref'], \n",
    "                                                          snp_info['alt'])):\n",
    "                        if pos in self.hapmap_to_1000g:\n",
    "                            ref_kg, alt_kg = self.hapmap_to_1000g[pos]\n",
    "                            if ref_kg != ref:\n",
    "                                mask = geno[i] != 1\n",
    "                                geno[i][mask] = 2 - geno[i][mask]\n",
    "                \n",
    "                # Add to joint matrices\n",
    "                if geno.size > 0:\n",
    "                    genotypes.append(geno)\n",
    "                    n_samples = geno.shape[1]\n",
    "                    pop_labels.extend([pop] * n_samples)\n",
    "                    dataset_labels.extend([dataset] * n_samples)\n",
    "                    sample_ids.extend(pop_data['individual']['sample_id'])\n",
    "\n",
    "        if not genotypes:\n",
    "            raise ValueError(\"No valid genotype data after filtering\")\n",
    "\n",
    "        joint_geno = np.vstack([g.T for g in genotypes]).T\n",
    "        \n",
    "        return {\n",
    "            'genotype': joint_geno,\n",
    "            'population': np.array(pop_labels),\n",
    "            'dataset': np.array(dataset_labels),\n",
    "            'sample_id': np.array(sample_ids)\n",
    "        }\n",
    "\n",
    "    def _get_common_positions(self):\n",
    "        \"\"\"Get positions common to all datasets with QC\"\"\"\n",
    "        positions_per_dataset = {}\n",
    "        \n",
    "        for dataset in self.data.keys():\n",
    "            dataset_positions = set()\n",
    "            for pop_data in self.data[dataset].values():\n",
    "                if pop_data is not None:\n",
    "                    dataset_positions.update(pop_data['snp']['position'])\n",
    "            positions_per_dataset[dataset] = dataset_positions\n",
    "        \n",
    "        return set.intersection(*positions_per_dataset.values())\n",
    "\n",
    "    def perform_pca(self, n_components=2):\n",
    "        \"\"\"Perform PCA with batch effect correction\"\"\"\n",
    "        print(\"Performing PCA analysis...\")\n",
    "\n",
    "        # Center and scale the data\n",
    "        genotype_data = self.joint_data['genotype'].copy()\n",
    "        \n",
    "        # Improved missing value imputation\n",
    "        for i in range(genotype_data.shape[0]):\n",
    "            row = genotype_data[i]\n",
    "            mask = row == -1\n",
    "            if np.any(mask):\n",
    "                # Impute missing values using population-specific means\n",
    "                for pop in self.shared_populations:\n",
    "                    pop_mask = (self.joint_data['population'] == pop) & ~mask\n",
    "                    if np.any(pop_mask):\n",
    "                        pop_mean = np.mean(row[pop_mask])\n",
    "                        pop_missing = (self.joint_data['population'] == pop) & mask\n",
    "                        row[pop_missing] = pop_mean\n",
    "        \n",
    "        # Standardize\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(genotype_data.T)\n",
    "        \n",
    "        # Perform PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        self.pca_results = pca.fit_transform(scaled_data)\n",
    "        self.explained_variance = pca.explained_variance_ratio_\n",
    "        \n",
    "        print(f\"Variance explained: {self.explained_variance * 100}\")\n",
    "\n",
    "    def plot_pca(self, save_path=None):\n",
    "        \"\"\"Enhanced PCA plot\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for pop in self.shared_populations:\n",
    "            for dataset in self.data_paths.keys():\n",
    "                mask = (self.joint_data['population'] == pop) & \\\n",
    "                      (self.joint_data['dataset'] == dataset)\n",
    "                \n",
    "                if np.any(mask):\n",
    "                    plt.scatter(\n",
    "                        self.pca_results[mask, 0],\n",
    "                        self.pca_results[mask, 1],\n",
    "                        c=self.population_colors[pop],\n",
    "                        marker='o' if dataset == 'hapmap3' else '^',\n",
    "                        label=f'{pop}-{dataset}',\n",
    "                        alpha=0.7,\n",
    "                        s=50\n",
    "                    )\n",
    "\n",
    "        plt.xlabel(f'PC1 ({self.explained_variance[0]:.1%} variance)')\n",
    "        plt.ylabel(f'PC2 ({self.explained_variance[1]:.1%} variance)')\n",
    "        plt.title('PCA of HapMap3 and 1000G Populations')\n",
    "        \n",
    "        legend_elements = []\n",
    "        for pop in self.shared_populations:\n",
    "            legend_elements.extend([\n",
    "                plt.Line2D([0], [0], marker='o', color='w',\n",
    "                          markerfacecolor=self.population_colors[pop],\n",
    "                          label=f'{pop}-HapMap3', markersize=8),\n",
    "                plt.Line2D([0], [0], marker='^', color='w',\n",
    "                          markerfacecolor=self.population_colors[pop],\n",
    "                          label=f'{pop}-1000G', markersize=8)\n",
    "            ])\n",
    "        \n",
    "        plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1),\n",
    "                  loc='upper left', borderaxespad=0.)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "def run_analysis(snp_mapping_file):\n",
    "    \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "    try:\n",
    "        analyzer = JointPopulationAnalyzer(snp_mapping_file)\n",
    "        analyzer.prepare_joint_analysis()\n",
    "        analyzer.perform_pca()\n",
    "        analyzer.plot_pca(\"joint_population_pca.png\")\n",
    "        return analyzer\n",
    "    except Exception as e:\n",
    "        print(f\"Analysis failed: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "afd8dea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 21715 SNP mappings\n",
      "\n",
      "Loading data for all populations...\n",
      "\n",
      "Processing ASW from hapmap3...\n",
      "Reading genotype file: ../data/filtered_hapmap3/ASW.geno\n",
      "Removed 235 SNPs failing QC\n",
      "Final genotype matrix shape: (21459, 49)\n",
      "Removed 1984 SNPs failing HWE\n",
      "Final data shapes - Genotype: (19475, 49), SNPs: 19475\n",
      "\n",
      "Processing CEU from hapmap3...\n",
      "Reading genotype file: ../data/filtered_hapmap3/CEU.geno\n",
      "Removed 387 SNPs failing QC\n",
      "Final genotype matrix shape: (21307, 112)\n",
      "Removed 1027 SNPs failing HWE\n",
      "Final data shapes - Genotype: (20280, 112), SNPs: 20280\n",
      "\n",
      "Processing CHB from hapmap3...\n",
      "Reading genotype file: ../data/filtered_hapmap3/CHB.geno\n",
      "Removed 190 SNPs failing QC\n",
      "Final genotype matrix shape: (21504, 84)\n",
      "Removed 1753 SNPs failing HWE\n",
      "Final data shapes - Genotype: (19751, 84), SNPs: 19751\n",
      "\n",
      "Processing JPT from hapmap3...\n",
      "Reading genotype file: ../data/filtered_hapmap3/JPT.geno\n",
      "Removed 200 SNPs failing QC\n",
      "Final genotype matrix shape: (21494, 86)\n",
      "Removed 1812 SNPs failing HWE\n",
      "Final data shapes - Genotype: (19682, 86), SNPs: 19682\n",
      "\n",
      "Processing LWK from hapmap3...\n",
      "Reading genotype file: ../data/filtered_hapmap3/LWK.geno\n",
      "Removed 273 SNPs failing QC\n",
      "Final genotype matrix shape: (21421, 90)\n",
      "Removed 1647 SNPs failing HWE\n",
      "Final data shapes - Genotype: (19774, 90), SNPs: 19774\n",
      "\n",
      "Processing MXL from hapmap3...\n",
      "Reading genotype file: ../data/filtered_hapmap3/MXL.geno\n",
      "Removed 537 SNPs failing QC\n",
      "Final genotype matrix shape: (21157, 50)\n",
      "Removed 2355 SNPs failing HWE\n",
      "Final data shapes - Genotype: (18802, 50), SNPs: 18802\n",
      "\n",
      "Processing TSI from hapmap3...\n",
      "Reading genotype file: ../data/filtered_hapmap3/TSI.geno\n",
      "Removed 161 SNPs failing QC\n",
      "Final genotype matrix shape: (21533, 88)\n",
      "Removed 1307 SNPs failing HWE\n",
      "Final data shapes - Genotype: (20226, 88), SNPs: 20226\n",
      "\n",
      "Processing YRI from hapmap3...\n",
      "Reading genotype file: ../data/filtered_hapmap3/YRI.geno\n",
      "Removed 321 SNPs failing QC\n",
      "Final genotype matrix shape: (21373, 113)\n",
      "Removed 1570 SNPs failing HWE\n",
      "Final data shapes - Genotype: (19803, 113), SNPs: 19803\n",
      "\n",
      "Processing ASW from 1000g...\n",
      "Reading genotype file: ../data/1000g/populations/ASW.geno\n",
      "Removed 17329 SNPs failing QC\n",
      "Final genotype matrix shape: (4335, 61)\n",
      "Removed 2644 SNPs failing HWE\n",
      "Final data shapes - Genotype: (1691, 61), SNPs: 1691\n",
      "\n",
      "Processing CEU from 1000g...\n",
      "Reading genotype file: ../data/1000g/populations/CEU.geno\n",
      "Removed 18729 SNPs failing QC\n",
      "Final genotype matrix shape: (2935, 99)\n",
      "Removed 1292 SNPs failing HWE\n",
      "Final data shapes - Genotype: (1643, 99), SNPs: 1643\n",
      "\n",
      "Processing CHB from 1000g...\n",
      "Reading genotype file: ../data/1000g/populations/CHB.geno\n",
      "Removed 19198 SNPs failing QC\n",
      "Final genotype matrix shape: (2466, 103)\n",
      "Removed 903 SNPs failing HWE\n",
      "Final data shapes - Genotype: (1563, 103), SNPs: 1563\n",
      "\n",
      "Processing JPT from 1000g...\n",
      "Reading genotype file: ../data/1000g/populations/JPT.geno\n",
      "Removed 19247 SNPs failing QC\n",
      "Final genotype matrix shape: (2417, 104)\n",
      "Removed 898 SNPs failing HWE\n",
      "Final data shapes - Genotype: (1519, 104), SNPs: 1519\n",
      "\n",
      "Processing LWK from 1000g...\n",
      "Reading genotype file: ../data/1000g/populations/LWK.geno\n",
      "Removed 16733 SNPs failing QC\n",
      "Final genotype matrix shape: (4931, 99)\n",
      "Removed 2984 SNPs failing HWE\n",
      "Final data shapes - Genotype: (1947, 99), SNPs: 1947\n",
      "\n",
      "Processing MXL from 1000g...\n",
      "Reading genotype file: ../data/1000g/populations/MXL.geno\n",
      "Removed 18836 SNPs failing QC\n",
      "Final genotype matrix shape: (2828, 64)\n",
      "Removed 1323 SNPs failing HWE\n",
      "Final data shapes - Genotype: (1505, 64), SNPs: 1505\n",
      "\n",
      "Processing TSI from 1000g...\n",
      "Reading genotype file: ../data/1000g/populations/TSI.geno\n",
      "Removed 18963 SNPs failing QC\n",
      "Final genotype matrix shape: (2701, 107)\n",
      "Removed 1061 SNPs failing HWE\n",
      "Final data shapes - Genotype: (1640, 107), SNPs: 1640\n",
      "\n",
      "Processing YRI from 1000g...\n",
      "Reading genotype file: ../data/1000g/populations/YRI.geno\n",
      "Removed 17318 SNPs failing QC\n",
      "Final genotype matrix shape: (4346, 108)\n",
      "Removed 2353 SNPs failing HWE\n",
      "Final data shapes - Genotype: (1993, 108), SNPs: 1993\n",
      "Using 21641 mapped positions\n",
      "Found 2777 common positions\n",
      "\n",
      "Processing ASW-hapmap3\n",
      "\n",
      "Processing CEU-hapmap3\n",
      "\n",
      "Processing CHB-hapmap3\n",
      "\n",
      "Processing JPT-hapmap3\n",
      "\n",
      "Processing LWK-hapmap3\n",
      "\n",
      "Processing MXL-hapmap3\n",
      "\n",
      "Processing TSI-hapmap3\n",
      "\n",
      "Processing YRI-hapmap3\n",
      "\n",
      "Processing ASW-1000g\n",
      "\n",
      "Processing CEU-1000g\n",
      "\n",
      "Processing CHB-1000g\n",
      "\n",
      "Processing JPT-1000g\n",
      "\n",
      "Processing LWK-1000g\n",
      "\n",
      "Processing MXL-1000g\n",
      "\n",
      "Processing TSI-1000g\n",
      "\n",
      "Processing YRI-1000g\n",
      "Analysis failed: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 2511 and the array at index 1 has size 2602\n"
     ]
    }
   ],
   "source": [
    "analyzer = run_analysis(\"../data/common_snps/common_snps.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa3ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
